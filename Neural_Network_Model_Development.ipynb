{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSTddQ5LTkn4veiaZXJyv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShuHuiK/WIE3007_Group_Assignment/blob/ShuHui/Neural_Network_Model_Development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "72Q_qkCYwG-6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score, precision_score, recall_score, roc_curve\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 1. LOAD DATA\n",
        "df = pd.read_csv('2025_Sterling_Financial_Dataset_clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. PREPROCESSING\n",
        "# Dropping non-predictive columns\n",
        "drop_cols = ['date', 'customer_id', 'customer_feedback', 'location']\n",
        "X = df.drop(columns=['default_history'] + drop_cols)\n",
        "y = df['default_history']\n",
        "\n",
        "# Defining numeric and categorical features\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Creating the transformer pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit and transform\n",
        "X_processed = preprocessor.fit_transform(X)"
      ],
      "metadata": {
        "id": "NJR3UlZPxMcP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. SPLIT DATA\n",
        "# Stratify ensures the minority class is represented in both sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y.values, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "GMxBsXE1xitI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. HANDLE CLASS IMBALANCE\n",
        "# Calculating weights to make the model \"pay more attention\" to the minority class (Default)\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: weights[i] for i in range(len(weights))}"
      ],
      "metadata": {
        "id": "ZMnLH2TcxvM6"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}